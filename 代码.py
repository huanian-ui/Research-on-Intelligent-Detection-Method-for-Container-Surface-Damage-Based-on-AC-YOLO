import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import os
from ultralytics import YOLO
import yaml
from tqdm import tqdm
import warnings
import json
from pathlib import Path
import copy
import time

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤ºå’Œç§‘ç ”é…è‰²
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

COLORS = ['#90D8A6', '#83A1E7', '#E992A9', '#D2CAF8', '#F7AF7F', '#B0D9F9', '#E7B6BC', '#B0CDED']


class AdvancedContainerAugmentation:
    def __init__(self, special_aug=True):
        self.special_aug = special_aug
        self.augmentations = {
            'corrosion_sim': lambda img: self.simulate_corrosion(img),
            'shadow_effect': lambda img: self.add_shadow(img),
            'reflection': lambda img: self.add_reflection(img),
            'rain_effect': lambda img: self.add_rain(img),
            'stain_effect': lambda img: self.add_stain(img),
            'rust_enhancement': lambda img: self.enhance_rusty_features(img),
            'contrast_adjust': lambda img: self.adjust_contrast(img),
            'noise_injection': lambda img: self.add_noise(img)
        }

    def simulate_corrosion(self, img):
        """æ¨¡æ‹Ÿé”ˆèš€æ•ˆæœ - ä¼˜åŒ–ç‰ˆæœ¬"""
        h, w = img.shape[:2]
        # æ·»åŠ è¤è‰²æ–‘ç‚¹æ¨¡æ‹Ÿé”ˆèš€
        for _ in range(np.random.randint(8, 25)):
            x, y = np.random.randint(0, w), np.random.randint(0, h)
            radius = np.random.randint(8, 25)
            # æ›´çœŸå®çš„é”ˆèš€é¢œè‰²
            color = [np.random.randint(80, 130), np.random.randint(40, 80), np.random.randint(0, 40)]
            cv2.circle(img, (x, y), radius, color, -1)
            # æ·»åŠ çº¹ç†æ•ˆæœ
            if radius > 15:
                for i in range(3):
                    offset_x = np.random.randint(-5, 5)
                    offset_y = np.random.randint(-5, 5)
                    cv2.circle(img, (x + offset_x, y + offset_y), radius // 2, color, -1)
        return img

    def add_shadow(self, img):
        """æ·»åŠ é˜´å½±æ•ˆæœ - ä¼˜åŒ–ç‰ˆæœ¬"""
        h, w = img.shape[:2]
        # åˆ›å»ºæ›´è‡ªç„¶çš„é˜´å½±
        shadow_mask = np.zeros((h, w), dtype=np.float32)

        # éšæœºç”Ÿæˆå¤šä¸ªé˜´å½±åŒºåŸŸ
        for _ in range(np.random.randint(2, 5)):
            center_x = np.random.randint(0, w)
            center_y = np.random.randint(0, h)
            radius_x = np.random.randint(50, 200)
            radius_y = np.random.randint(50, 200)

            # åˆ›å»ºæ¤­åœ†é˜´å½±
            y_coords, x_coords = np.ogrid[:h, :w]
            mask = ((x_coords - center_x) ** 2 / radius_x ** 2 +
                    (y_coords - center_y) ** 2 / radius_y ** 2 <= 1)
            shadow_mask[mask] = np.random.uniform(0.3, 0.7)

        # åº”ç”¨é«˜æ–¯æ¨¡ç³Šä½¿é˜´å½±æ›´è‡ªç„¶
        shadow_mask = cv2.GaussianBlur(shadow_mask, (51, 51), 0)
        shadow_mask = np.stack([shadow_mask] * 3, axis=-1)

        img = img.astype(np.float32)
        img = img * (1 - shadow_mask * 0.4)  # è°ƒæ•´é˜´å½±å¼ºåº¦
        return np.clip(img, 0, 255).astype(np.uint8)

    def add_reflection(self, img):
        """æ·»åŠ åå…‰æ•ˆæœ - ä¼˜åŒ–ç‰ˆæœ¬"""
        h, w = img.shape[:2]
        # åˆ›å»ºé«˜å…‰åŒºåŸŸ
        reflection_mask = np.zeros((h, w), dtype=np.float32)

        # ç”Ÿæˆå¤šä¸ªåå…‰åŒºåŸŸ
        for _ in range(np.random.randint(1, 3)):
            center_x = np.random.randint(w // 4, 3 * w // 4)
            center_y = np.random.randint(h // 4, 3 * h // 4)
            axes_x = np.random.randint(30, 100)
            axes_y = np.random.randint(30, 100)
            angle = np.random.randint(0, 180)

            # åˆ›å»ºæ¤­åœ†åå…‰åŒºåŸŸ
            cv2.ellipse(reflection_mask, (center_x, center_y), (axes_x, axes_y),
                        angle, 0, 360, 1, -1)

        # åº”ç”¨é«˜æ–¯æ¨¡ç³Š
        reflection_mask = cv2.GaussianBlur(reflection_mask, (0, 0), 25)
        reflection_mask = np.stack([reflection_mask] * 3, axis=-1)

        img = img.astype(np.float32)
        img = img + reflection_mask * 80  # å¢åŠ äº®åº¦
        return np.clip(img, 0, 255).astype(np.uint8)

    def add_rain(self, img):
        """æ·»åŠ é›¨æ°´æ•ˆæœ - ä¼˜åŒ–ç‰ˆæœ¬"""
        h, w = img.shape[:2]
        # åˆ›å»ºé›¨æ»´æ•ˆæœ
        rain_layer = np.zeros((h, w, 3), dtype=np.uint8)

        # æ·»åŠ é›¨æ»´æ¡çº¹
        for _ in range(np.random.randint(80, 150)):
            x1 = np.random.randint(0, w)
            y1 = np.random.randint(-50, 0)  # ä»å›¾åƒå¤–å¼€å§‹
            length = np.random.randint(20, 40)
            thickness = np.random.randint(1, 3)
            brightness = np.random.randint(180, 230)

            cv2.line(rain_layer, (x1, y1), (x1, y1 + length),
                     (brightness, brightness, brightness), thickness)

        # æ¨¡ç³Šé›¨æ»´
        rain_layer = cv2.GaussianBlur(rain_layer, (3, 3), 0)

        # èåˆé›¨æ»´æ•ˆæœ
        img = cv2.addWeighted(img, 0.8, rain_layer, 0.2, 0)
        return img

    def add_stain(self, img):
        """æ·»åŠ æ±¡æ¸æ•ˆæœ - ä¼˜åŒ–ç‰ˆæœ¬"""
        h, w = img.shape[:2]
        # æ·»åŠ éšæœºæ±¡æ¸
        for _ in range(np.random.randint(4, 10)):
            x, y = np.random.randint(0, w), np.random.randint(0, h)
            radius = np.random.randint(15, 40)

            # åˆ›å»ºä¸è§„åˆ™çš„æ±¡æ¸å½¢çŠ¶
            stain_mask = np.zeros((h, w), dtype=np.uint8)
            cv2.circle(stain_mask, (x, y), radius, 255, -1)

            # æ·»åŠ å˜å½¢ä½¿æ±¡æ¸æ›´è‡ªç„¶
            kernel = np.ones((15, 15), np.uint8)
            stain_mask = cv2.erode(stain_mask, kernel, iterations=1)
            stain_mask = cv2.dilate(stain_mask, kernel, iterations=1)

            # åº”ç”¨æ±¡æ¸é¢œè‰²
            stain_color = np.random.randint(40, 80, 3)
            stain_area = np.where(stain_mask[..., None] > 0)
            if len(stain_area[0]) > 0:
                img[stain_area] = cv2.addWeighted(
                    img[stain_area], 0.7,
                    np.full_like(img[stain_area], stain_color), 0.3, 0
                )

        return img

    def enhance_rusty_features(self, img):
        """ä¸“é—¨å¢å¼ºé”ˆèš€ç‰¹å¾"""
        if np.random.random() < 0.6:  # 60%æ¦‚ç‡åº”ç”¨
            # è°ƒæ•´è‰²è°ƒåå‘è¤è‰²
            hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV).astype(np.float32)
            # åœ¨è‰²è°ƒé€šé“å¢åŠ è¤è‰²åˆ†é‡
            hsv[:, :, 0] = np.clip(hsv[:, :, 0] * np.random.uniform(0.9, 1.1), 0, 179)
            # å¢åŠ é¥±å’Œåº¦ä½¿é¢œè‰²æ›´é²œè‰³
            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * np.random.uniform(1.0, 1.3), 0, 255)
            img = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)

            # æ·»åŠ é”ˆèš€çº¹ç†
            img = self.simulate_corrosion(img)

        return img

    def adjust_contrast(self, img):
        """è°ƒæ•´å¯¹æ¯”åº¦"""
        alpha = np.random.uniform(0.8, 1.2)  # å¯¹æ¯”åº¦å› å­
        beta = np.random.randint(-10, 10)  # äº®åº¦è°ƒæ•´
        img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)
        return img

    def add_noise(self, img):
        """æ·»åŠ å™ªå£°"""
        if np.random.random() < 0.3:  # 30%æ¦‚ç‡æ·»åŠ å™ªå£°
            noise = np.random.normal(0, 5, img.shape).astype(np.float32)
            img = img.astype(np.float32) + noise
            img = np.clip(img, 0, 255).astype(np.uint8)
        return img

    def apply(self, img):
        """åº”ç”¨å¢å¼º"""
        if self.special_aug and np.random.random() < 0.8:  # 80%æ¦‚ç‡åº”ç”¨å¢å¼º
            # éšæœºé€‰æ‹©1-3ç§å¢å¼ºæ–¹æ³•
            num_augmentations = np.random.randint(1, 4)
            augment_types = np.random.choice(
                list(self.augmentations.keys()),
                num_augmentations,
                replace=False
            )

            for aug_type in augment_types:
                img = self.augmentations[aug_type](img)

        return img


class ContainerDataset(Dataset):
    def __init__(self, images_dir, labels_dir, class_names, img_size=640,
                 augment=False, balance_data=True, special_aug=True):
        self.images_dir = images_dir
        self.labels_dir = labels_dir
        self.img_size = img_size
        self.augment = augment
        self.augmentor = AdvancedContainerAugmentation(special_aug)
        self.class_names = class_names

        # è·å–æ‰€æœ‰å›¾åƒå’Œæ ‡ç­¾æ–‡ä»¶
        self.image_files = sorted([f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png'))])
        self.label_files = [f.replace('.jpg', '.txt').replace('.png', '.txt') for f in self.image_files]

        # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
        self.class_counts = {i: 0 for i in range(len(class_names))}
        self.valid_samples = []

        for img_file, label_file in zip(self.image_files, self.label_files):
            label_path = os.path.join(labels_dir, label_file)
            if os.path.exists(label_path):
                with open(label_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if lines:
                        self.valid_samples.append((img_file, label_file))
                        for line in lines:
                            class_id = int(line.strip().split()[0])
                            if class_id in self.class_counts:
                                self.class_counts[class_id] += 1

        print("åŸå§‹ç±»åˆ«åˆ†å¸ƒ:", self.class_counts)

        # æ•°æ®å¹³è¡¡ç­–ç•¥
        if balance_data:
            self.samples = self._balance_dataset()
        else:
            self.samples = self.valid_samples

        print(f"æœ€ç»ˆè®­ç»ƒæ ·æœ¬æ•°: {len(self.samples)}")
        print(f"å¹³è¡¡åç±»åˆ«åˆ†å¸ƒ: {self._get_balanced_distribution()}")

    def _get_balanced_distribution(self):
        """è·å–å¹³è¡¡åçš„ç±»åˆ«åˆ†å¸ƒ"""
        balanced_counts = {i: 0 for i in range(len(self.class_names))}
        for img_file, label_file in self.samples:
            label_path = os.path.join(self.labels_dir, label_file)
            if os.path.exists(label_path):
                with open(label_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    for line in lines:
                        class_id = int(line.strip().split()[0])
                        if class_id in balanced_counts:
                            balanced_counts[class_id] += 1
        return balanced_counts

    def _balance_dataset(self):
        """ä½¿ç”¨è¿‡é‡‡æ ·å¹³è¡¡æ•°æ®é›†"""
        max_count = max(self.class_counts.values()) if self.class_counts else 0
        if max_count == 0:
            return self.valid_samples

        balanced_samples = []
        class_weights = {}

        for class_id, count in self.class_counts.items():
            if count > 0:
                class_weights[class_id] = max_count / count
            else:
                class_weights[class_id] = 1.0

        for img_file, label_file in self.valid_samples:
            label_path = os.path.join(self.labels_dir, label_file)
            with open(label_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                max_weight = 0
                for line in lines:
                    class_id = int(line.strip().split()[0])
                    max_weight = max(max_weight, class_weights[class_id])

                sample_times = min(int(max_weight) + 1, 5)
                for _ in range(sample_times):
                    balanced_samples.append((img_file, label_file))

        return balanced_samples

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_file, label_file = self.samples[idx]
        img_path = os.path.join(self.images_dir, img_file)
        label_path = os.path.join(self.labels_dir, label_file)

        # åŠ è½½å›¾åƒ
        img = cv2.imread(img_path)
        if img is None:
            img = np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8)
            return (torch.from_numpy(img).permute(2, 0, 1).float() / 255.0,
                    torch.zeros((0, 6)))

        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # åº”ç”¨æ•°æ®å¢å¼º
        if self.augment:
            img = self.augmentor.apply(img)

        # è°ƒæ•´å›¾åƒå¤§å°
        img = cv2.resize(img, (self.img_size, self.img_size))
        img = img.astype(np.float32) / 255.0

        # åŠ è½½æ ‡ç­¾
        bboxes = []
        if os.path.exists(label_path):
            with open(label_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                for line in lines:
                    data = line.strip().split()
                    if len(data) == 5:
                        class_id = int(data[0])
                        x_center = float(data[1])
                        y_center = float(data[2])
                        width = float(data[3])
                        height = float(data[4])
                        bboxes.append([class_id, x_center, y_center, width, height])

        # è½¬æ¢ä¸ºTensor
        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float()

        # å‡†å¤‡ç›®æ ‡å¼ é‡
        if len(bboxes) > 0:
            targets = torch.zeros((len(bboxes), 6))
            for i, bbox in enumerate(bboxes):
                targets[i, 0] = 0
                targets[i, 1] = bbox[0]
                targets[i, 2] = bbox[1]
                targets[i, 3] = bbox[2]
                targets[i, 4] = bbox[3]
                targets[i, 5] = bbox[4]
        else:
            targets = torch.zeros((0, 6))

        return img_tensor, targets


class AdvancedContainerDamageDetector:
    def __init__(self, model_path='yolo11s.pt', num_classes=3):
        self.model_path = model_path
        self.num_classes = num_classes
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f'ä½¿ç”¨è®¾å¤‡: {self.device}')

        # è®­ç»ƒå†å²è®°å½•
        self.training_history = {}

    def _create_new_model(self):
        """åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹"""
        try:
            # æ¸…ç†GPUç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
            self.model = YOLO(self.model_path)
            return True
        except Exception as e:
            print(f"åˆ›å»ºæ¨¡å‹å¤±è´¥: {e}")
            return False

    def setup_dataset(self, data_config, config_name):
        """è®¾ç½®æ•°æ®é›†é…ç½®"""
        config = {
            'path': './æ•°æ®é›†3713',
            'train': 'images/train',
            'val': 'images/train',
            'test': 'images/test',
            'nc': self.num_classes,
            'names': ['dent', 'hole', 'rusty']
        }

        with open(data_config, 'w', encoding='utf-8') as f:
            yaml.dump(config, f)

        self.training_history[config_name] = {
            'config_file': data_config,
            'start_time': None,
            'end_time': None,
            'metrics': {}
        }

        return data_config

    def train(self, config_name, epochs=300, balance_data=True,
              augment=True, special_aug=True, lr=0.001):
        """è®­ç»ƒæ¨¡å‹"""
        # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
        if not self._create_new_model():
            return None

        # å‡†å¤‡æ•°æ®é›†é…ç½®
        data_config = f'{config_name}_data.yaml'
        config_file = self.setup_dataset(data_config, config_name)

        # ä¿®æ­£é¡¹ç›®åç§°è·¯å¾„
        project_name = f"runs/detect/ablations_{config_name}"

        # è®­ç»ƒå‚æ•°
        train_args = {
            'data': config_file,
            'epochs': epochs,
            'imgsz': 640,
            'batch': 16,
            'device': 0 if torch.cuda.is_available() else 'cpu',
            'workers': 4,  # å‡å°‘workersæ•°é‡
            'patience': 50,  # å‡å°‘patience
            'save': True,
            'exist_ok': True,
            'pretrained': True,
            'optimizer': 'AdamW',
            'lr0': lr,
            'weight_decay': 0.0005,
            'augment': augment,
            'cos_lr': True,
            'label_smoothing': 0.1,
            'dropout': 0.1,
            'verbose': False,
            'project': 'runs/detect',
            'name': f'ablations_{config_name}',
        }

        # åªæœ‰åœ¨å¯ç”¨å¢å¼ºæ—¶æ‰æ·»åŠ è¿™äº›å‚æ•°
        if augment:
            train_args['mixup'] = 0.1
            train_args['copy_paste'] = 0.1

        print(f"å¼€å§‹è®­ç»ƒé…ç½®: {config_name}")
        print(f"è®­ç»ƒå‚æ•°: epochs={epochs}, balance_data={balance_data}, "
              f"augment={augment}, special_aug={special_aug}, lr={lr}")

        # è®°å½•å¼€å§‹æ—¶é—´
        self.training_history[config_name]['start_time'] = pd.Timestamp.now()

        # å¼€å§‹è®­ç»ƒ
        try:
            results = self.model.train(**train_args)
            self.training_history[config_name]['results'] = "è®­ç»ƒå®Œæˆ"
        except Exception as e:
            print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            self.training_history[config_name]['error'] = str(e)
            return None

        # è®°å½•ç»“æŸæ—¶é—´
        self.training_history[config_name]['end_time'] = pd.Timestamp.now()

        return "è®­ç»ƒå®Œæˆ"

    def save_training_history(self):
        """ä¿å­˜è®­ç»ƒå†å²"""
        history_file = 'training_history.json'

        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_history = {}
        for config_name, history in self.training_history.items():
            serializable_history[config_name] = {
                'config_file': history.get('config_file'),
                'start_time': str(history.get('start_time')),
                'end_time': str(history.get('end_time')),
                'test_metrics': history.get('test_metrics', {}),
                'error': history.get('error')
            }

        try:
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_history, f, indent=2, ensure_ascii=False)

            print(f"è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {history_file}")
            return True
        except Exception as e:
            print(f"ä¿å­˜è®­ç»ƒå†å²å¤±è´¥: {e}")
            # å°è¯•ç®€åŒ–ä¿å­˜
            try:
                simplified_history = {}
                for config_name, history in self.training_history.items():
                    simplified_history[config_name] = {
                        'config_file': history.get('config_file'),
                        'start_time': str(history.get('start_time')),
                        'end_time': str(history.get('end_time')),
                        'error': history.get('error')
                    }

                with open('simplified_training_history.json', 'w', encoding='utf-8') as f:
                    json.dump(simplified_history, f, indent=2, ensure_ascii=False)
                print("ç®€åŒ–ç‰ˆè®­ç»ƒå†å²å·²ä¿å­˜")
                return True
            except Exception as e2:
                print(f"è¿ç®€åŒ–ç‰ˆä¹Ÿæ— æ³•ä¿å­˜: {e2}")
                return False


def evaluate_on_test_fixed(detector, config_name):
    """ä¿®å¤ç‰ˆæœ¬çš„æµ‹è¯•é›†è¯„ä¼°å‡½æ•°"""
    # ä¿®æ­£æ¨¡å‹è·¯å¾„ - ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„æ ¼å¼
    best_model_path = f'runs/detect/ablations_{config_name}/weights/best.pt'

    # æ£€æŸ¥å¤šä¸ªå¯èƒ½çš„è·¯å¾„
    possible_paths = [
        best_model_path,
        f'ablation_studies/ablations_{config_name}/weights/best.pt',
        f'./ablation_studies/ablations_{config_name}/weights/best.pt',
        f'./runs/detect/ablations_{config_name}/weights/best.pt'
    ]

    found_path = None
    for path in possible_paths:
        if os.path.exists(path):
            found_path = path
            break

    if found_path:
        print(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {found_path}")
        try:
            # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹è¿›è¡Œè¯„ä¼°
            eval_model = YOLO(found_path)
            metrics = eval_model.val(split='test')

            # å®‰å…¨åœ°æå–æŒ‡æ ‡å€¼ï¼Œå¤„ç†å¯èƒ½çš„æ•°ç»„æƒ…å†µ
            precision = getattr(metrics.box, 'p', 0.5) if hasattr(metrics, 'box') else 0.5
            recall = getattr(metrics.box, 'r', 0.5) if hasattr(metrics, 'box') else 0.5
            map50 = getattr(metrics.box, 'map50', 0.5) if hasattr(metrics, 'box') else 0.5
            map50_95 = getattr(metrics.box, 'map', 0.5) if hasattr(metrics, 'box') else 0.5

            # å¤„ç†æ•°ç»„æƒ…å†µï¼šå¦‚æœæ˜¯æ•°ç»„ï¼Œå–å¹³å‡å€¼
            if hasattr(precision, '__iter__'):
                precision = float(np.mean(precision))
            if hasattr(recall, '__iter__'):
                recall = float(np.mean(recall))
            if hasattr(map50, '__iter__'):
                map50 = float(np.mean(map50))
            if hasattr(map50_95, '__iter__'):
                map50_95 = float(np.mean(map50_95))

            # è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
            test_metrics = {
                'precision': float(precision),
                'recall': float(recall),
                'mAP50': float(map50),
                'mAP50_95': float(map50_95)
            }

            # ä¿å­˜è¯„ä¼°ç»“æœ
            detector.training_history[config_name]['test_metrics'] = test_metrics

            return test_metrics
        except Exception as e:
            print(f"è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
    else:
        print(f"æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼Œæ£€æŸ¥ä»¥ä¸‹è·¯å¾„:")
        for path in possible_paths:
            print(f"  - {path}")
        return None


def run_comprehensive_ablation_study():
    """è¿è¡Œç®€åŒ–çš„æ¶ˆèå®éªŒ - åªè®­ç»ƒ3ä¸ªæ¨¡å‹"""

    # ç®€åŒ–çš„æ¶ˆèå®éªŒé…ç½®ï¼ˆåªä¿ç•™3ä¸ªå…³é”®é…ç½®ï¼‰
    configurations = {
        'baseline': {
            'balance_data': False,
            'augment': False,
            'special_aug': False,
            'lr': 0.001,
            'description': 'åŸºçº¿YOLO11s'
        },
        'balance_only': {
            'balance_data': True,
            'augment': False,
            'special_aug': False,
            'lr': 0.001,
            'description': 'ä»…æ•°æ®å¹³è¡¡'
        },
        'full_augmentation': {
            'balance_data': True,
            'augment': True,
            'special_aug': True,
            'lr': 0.0005,
            'description': 'å®Œæ•´å¢å¼ºç­–ç•¥'
        }
    }

    ablation_results = {}

    # è¿è¡Œæ¯ä¸ªé…ç½®çš„å®éªŒ - ä¸ºæ¯ä¸ªå®éªŒåˆ›å»ºæ–°çš„æ£€æµ‹å™¨å®ä¾‹
    for config_name, params in configurations.items():
        print(f"\n{'=' * 60}")
        print(f"å¼€å§‹æ¶ˆèå®éªŒ: {config_name}")
        print(f"æè¿°: {params['description']}")
        print(f"å‚æ•°: {params}")
        print(f"{'=' * 60}")

        # ä¸ºæ¯ä¸ªå®éªŒåˆ›å»ºæ–°çš„æ£€æµ‹å™¨å®ä¾‹
        detector = AdvancedContainerDamageDetector(model_path='yolo11s.pt', num_classes=3)

        try:
            # è®­ç»ƒæ¨¡å‹
            training_results = detector.train(
                config_name=config_name,
                epochs=300,
                balance_data=params['balance_data'],
                augment=params['augment'],
                special_aug=params['special_aug'],
                lr=params['lr']
            )

            if training_results is not None:
                print(f"âœ… {config_name} è®­ç»ƒå®Œæˆ!")

                # ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿æ–‡ä»¶ä¿å­˜
                time.sleep(5)

                # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
                test_metrics = evaluate_on_test_fixed(detector, config_name)

                if test_metrics is not None:
                    ablation_results[config_name] = {
                        'description': params['description'],
                        'params': params,
                        'training_time': str(detector.training_history[config_name]['end_time'] -
                                             detector.training_history[config_name]['start_time']),
                        'test_metrics': test_metrics,
                        'mAP50': test_metrics['mAP50'],
                        'mAP50_95': test_metrics['mAP50_95']
                    }

                    print(f"âœ… {config_name} è¯„ä¼°å®Œæˆ!")
                    print(f"æµ‹è¯•mAP50: {test_metrics['mAP50']:.4f}")
                    print(f"æµ‹è¯•mAP50-95: {test_metrics['mAP50_95']:.4f}")
                else:
                    print(f"âŒ {config_name} è¯„ä¼°å¤±è´¥")
                    ablation_results[config_name] = {
                        'description': params['description'],
                        'error': 'è¯„ä¼°å¤±è´¥'
                    }
            else:
                print(f"âŒ {config_name} è®­ç»ƒå¤±è´¥")
                ablation_results[config_name] = {
                    'description': params['description'],
                    'error': 'è®­ç»ƒå¤±è´¥'
                }

        except Exception as e:
            print(f"âŒ {config_name} æ‰§è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            ablation_results[config_name] = {
                'description': params['description'],
                'error': str(e)
            }

        # ä¿å­˜å½“å‰å®éªŒçš„è®­ç»ƒå†å²ï¼ˆç®€åŒ–ç‰ˆï¼‰
        try:
            detector.save_training_history()
        except Exception as e:
            print(f"ä¿å­˜è®­ç»ƒå†å²å¤±è´¥: {e}")

        # æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        # å®éªŒé—´æš‚åœ
        print("ç­‰å¾…5ç§’åå¼€å§‹ä¸‹ä¸€ä¸ªå®éªŒ...")
        time.sleep(5)

    return ablation_results


def visualize_ablation_results_comprehensive(results):
    """ç®€åŒ–ç‰ˆçš„å¯è§†åŒ–æ¶ˆèå®éªŒç»“æœ"""
    if not results:
        print("æ²¡æœ‰å¯ç”¨çš„ç»“æœè¿›è¡Œå¯è§†åŒ–")
        return

    # å‡†å¤‡æ•°æ®
    config_names = []
    map50_scores = []
    map50_95_scores = []
    descriptions = []

    for config_name, result in results.items():
        if 'mAP50' in result and 'mAP50_95' in result and result.get('error') is None:
            config_names.append(config_name)
            map50_scores.append(result['mAP50'])
            map50_95_scores.append(result['mAP50_95'])
            descriptions.append(result['description'])

    if not config_names:
        print("æ²¡æœ‰æœ‰æ•ˆçš„æŒ‡æ ‡æ•°æ®")
        return

    # åˆ›å»ºç®€åŒ–å¯è§†åŒ–
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # 1. mAP50å¯¹æ¯”
    bars1 = ax1.bar(config_names, map50_scores, color=COLORS[:len(config_names)], alpha=0.8)
    ax1.set_title('æ¶ˆèå®éªŒ - mAP@0.5å¯¹æ¯”', fontsize=14, fontweight='bold', pad=20)
    ax1.set_ylabel('mAP@0.5', fontsize=12)
    ax1.tick_params(axis='x', rotation=45)
    ax1.grid(True, alpha=0.3)

    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
    for bar, value in zip(bars1, map50_scores):
        ax1.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                 f'{value:.3f}', ha='center', va='bottom', fontweight='bold')

    # 2. mAP50-95å¯¹æ¯”
    bars2 = ax2.bar(config_names, map50_95_scores, color=COLORS[len(config_names):], alpha=0.8)
    ax2.set_title('æ¶ˆèå®éªŒ - mAP@0.5:0.95å¯¹æ¯”', fontsize=14, fontweight='bold', pad=20)
    ax2.set_ylabel('mAP@0.5:0.95', fontsize=12)
    ax2.tick_params(axis='x', rotation=45)
    ax2.grid(True, alpha=0.3)

    for bar, value in zip(bars2, map50_95_scores):
        ax2.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005,
                 f'{value:.3f}', ha='center', va='bottom', fontweight='bold')

    plt.tight_layout()
    plt.savefig('simplified_ablation_results.png', dpi=300, bbox_inches='tight')
    plt.show()

    # ä¿å­˜ç»“æœä¸ºè¡¨æ ¼
    results_df = pd.DataFrame([
        {
            'é…ç½®': config_name,
            'æè¿°': result['description'],
            'mAP50': result.get('mAP50', 0),
            'mAP50_95': result.get('mAP50_95', 0),
            'è®­ç»ƒæ—¶é—´': result.get('training_time', 'N/A')
        }
        for config_name, result in results.items()
    ])

    results_df.to_csv('simplified_ablation_results.csv', index=False, encoding='utf-8-sig')
    print("æ¶ˆèå®éªŒç»“æœå·²ä¿å­˜åˆ° simplified_ablation_results.csv")

    # æ‰“å°æœ€ä½³é…ç½®
    if map50_scores:
        best_idx = np.argmax(map50_scores)
        best_config = config_names[best_idx]
        best_score = map50_scores[best_idx]
        print(f"\nğŸ‰ æœ€ä½³é…ç½®: {best_config}")
        print(f"æœ€ä½³mAP50: {best_score:.4f}")
        print(f"é…ç½®æè¿°: {descriptions[best_idx]}")


def analyze_training_curves():
    """åˆ†æè®­ç»ƒæ›²çº¿"""
    ablation_dirs = [
        'runs/detect/ablations_baseline',
        'runs/detect/ablations_balance_only',
        'runs/detect/ablations_full_augmentation'
    ]

    fig, axes = plt.subplots(2, 2, figsize=(20, 16))
    axes = axes.ravel()

    metrics_to_plot = [
        ('train/box_loss', 'è®­ç»ƒè¾¹ç•Œæ¡†æŸå¤±'),
        ('train/cls_loss', 'è®­ç»ƒåˆ†ç±»æŸå¤±'),
        ('metrics/mAP50(B)', 'mAP@0.5'),
        ('metrics/mAP50-95(B)', 'mAP@0.5:0.95')
    ]

    for idx, (metric, title) in enumerate(metrics_to_plot):
        for dir_path in ablation_dirs:
            results_file = os.path.join(dir_path, 'results.csv')
            if os.path.exists(results_file):
                config_name = os.path.basename(dir_path).replace('ablations_', '')
                results = pd.read_csv(results_file)

                if metric in results.columns:
                    # åªå–å‰100ä¸ªepochï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    data = results[metric].dropna().values[:300]
                    epochs = range(1, len(data) + 1)

                    axes[idx].plot(epochs, data, label=config_name, linewidth=2)

        axes[idx].set_title(title, fontsize=14, fontweight='bold')
        axes[idx].set_xlabel('è®­ç»ƒè½®æ¬¡')
        axes[idx].set_ylabel(metric.split('/')[-1])
        axes[idx].legend()
        axes[idx].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('training_curves_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()


def main():
    print("å¼€å§‹é›†è£…ç®±ç ´æŸæ£€æµ‹ç®€åŒ–æ¶ˆèå®éªŒ...")
    print(f"å¼€å§‹æ—¶é—´: {pd.Timestamp.now()}")

    # è¿è¡Œç®€åŒ–çš„æ¶ˆèå®éªŒï¼ˆ3ä¸ªæ¨¡å‹ï¼‰
    ablation_results = run_comprehensive_ablation_study()

    # å¯è§†åŒ–ç»“æœ
    if ablation_results:
        visualize_ablation_results_comprehensive(ablation_results)
        analyze_training_curves()
    else:
        print("æ¶ˆèå®éªŒæ²¡æœ‰äº§ç”Ÿæœ‰æ•ˆç»“æœ")

    print(f"\nå®éªŒå®Œæˆæ—¶é—´: {pd.Timestamp.now()}")
    print("æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")


if __name__ == "__main__":
    main()